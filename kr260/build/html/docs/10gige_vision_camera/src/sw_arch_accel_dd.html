<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
<!-- OneTrust Cookies Consent Notice start for xilinx.github.io -->

<script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="03af8d57-0a04-47a6-8f10-322fa00d8fc7" ></script>
<script type="text/javascript">
function OptanonWrapper() { }
</script>
<!-- OneTrust Cookies Consent Notice end for xilinx.github.io -->
<!-- Google Tag Manager -->
<script type="text/plain" class="optanon-category-C0002">(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-5RHQV7');</script>
<!-- End Google Tag Manager -->
  <title>Software Architecture of the Accelerator &mdash; Kria™ KR260 2022.1 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Debug" href="debug.html" />
    <link rel="prev" title="Software Architecture of the Platform" href="sw_arch_platform_dd.html" /> 
</head>

<body class="wy-body-for-nav">

<!-- Google Tag Manager -->
<noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-5RHQV7" height="0" width="0" style="display:none;visibility:hidden" class="optanon-category-C0002"></iframe></noscript>
<!-- End Google Tag Manager --> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
            <a href="../../../index.html" class="icon icon-home"> Kria™ KR260
            <img src="../../../_static/xilinx-header-logo.svg" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                2022.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">SOM</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/">Landing Page</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/Kria_doc_map/map.htm">Kria Adventure Map</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/creating_applications.html">Application Development</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/ubuntu_support.html">Ubuntu Support</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/bootfw.html">Boot Firmware</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/openamp.html">OpenAMP</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/dfx.html">Dynamic Function eXchange</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/yocto.html">Yocto Support</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/xen.html">XEN Support</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/freertos.html">FreeRTOS Support</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/kd240-docs.html">Kria KD240</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/kv260-docs.html">Kria KV260</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/kr260-docs.html">Kria KR260</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/KRS/">Kria Robotics Stack</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">KR260 Applications</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../10gige_vision_camera_landing.html">10GigE Vision Camera</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../10gige_vision_camera_landing.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../10gige_vision_camera_landing.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../10gige_vision_camera_landing.html#quick-start">Quick Start</a></li>
<li class="toctree-l2"><a class="reference internal" href="../10gige_vision_camera_landing.html#tutorials">Tutorials</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../10gige_vision_camera_landing.html#architecture">Architecture</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="10gige.html">Hardware Architecture of the Platform</a></li>
<li class="toctree-l3"><a class="reference internal" href="hw_arch_accel_dd.html">Hardware Architecture of the Accelerator</a></li>
<li class="toctree-l3"><a class="reference internal" href="sw_arch_platform_dd.html">Software Architecture of the Platform</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Software Architecture of the Accelerator</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="#vvas-plugins">VVAS Plugins</a></li>
<li class="toctree-l4"><a class="reference internal" href="#next-steps">Next Steps</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../10gige_vision_camera_landing.html#repositories">Repositories</a></li>
<li class="toctree-l2"><a class="reference internal" href="../10gige_vision_camera_landing.html#other">Other</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../ros2_multinode_communication_via_tsn/ros2_multinode_communication_via_tsn_landing.html">ROS 2 Multi-Node Communications via TSN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ros2_perception_node/ros2_perception_node_landing.html">ROS 2 Perception Node</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../gps_1588_ptp/gps_1588_ptp_precision_time_mgmt.html">Precision Time Management</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../bist/bist_landing.html">Built-In Self Test (BIST)</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: black" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Kria™ KR260</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../10gige_vision_camera_landing.html">10GigE Machine Vision Camera - Defect Detect</a> &raquo;</li>
      <li>Software Architecture of the Accelerator</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/docs/10gige_vision_camera/src/sw_arch_accel_dd.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <table class="sphinxhide">
 <tr>
   <td align="center"><img src="https://raw.githubusercontent.com/Xilinx/Image-Collateral/main/xilinx-logo.png" width="30%"/><h1>Kria&trade; KR260 Robotics Starter Kit</h1>
   </td>
 </tr>
 <tr>
 <td align="center"><h1>Machine Vision Camera Tutorial</h1> </td>
 </tr>
</table><div class="section" id="software-architecture-of-the-accelerator">
<h1>Software Architecture of the Accelerator<a class="headerlink" href="#software-architecture-of-the-accelerator" title="Permalink to this heading">¶</a></h1>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading">¶</a></h2>
<p>The MV-Defect-Detect application can take video input from a live or a file source. Two separate designs (and thus bitstreams) are provided, one supports monochrome input (GRAY), the other support color input (RGB). The image to be displayed can be taken from various stages of the pipeline: directly from the source (Gray or Color depending on the sensor), after the preprocessing stage, or after the cca plus text overlay stage. The AMD Vitis™ overlay includes Vitis Vision libraries that process the frames and detect defects in mangoes.</p>
<p>In this reference design, the resolution of the input frames is 1920x1080, and the outputs are 1920x1080 on a 1080p display. If an image sensor is used instead of file source, the sensor resolution is fixed at 2472x2128. As part of the sensor capture pipeline, 64 lines of optical black at the top of the image are cropped resulting in 2472x2064; after that the ISP downsizes the image to 1920x1080, in case of color sensor debayers the image, and generally improves the image quality.</p>
<p><img alt="../../../_images/defect-detection-process.png" src="../../../_images/defect-detection-process.png" /></p>
<p>The source and sink pipeline elements are standard GStreamer plugins, such as <em>filesrc</em> for file input, <em>v4l2src</em> for camera capture, <em>kmssink</em> for the display, or <em>filesink</em> for file output. Refer to the <a class="reference external" href="https://gstreamer.freedesktop.org/documentation/tutorials/index.html?gi-language=c">GStreamer documentation</a> for detailed usage.</p>
</div>
<div class="section" id="vvas-plugins">
<h2>VVAS Plugins<a class="headerlink" href="#vvas-plugins" title="Permalink to this heading">¶</a></h2>
<p>The core acceleration tasks are performed by the, Otsu, Pre-Process and CCA libraries, which are developed by AMD based on the Vitis Vision library functions. The following table lists the VVAS GStreamer plugins used in this application.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Kernel Name</th>
<th>GStreamer Plugin</th>
<th>Description</th>
<th>Resource Type</th>
</tr>
</thead>
<tbody>
<tr>
<td>Otsu</td>
<td>VVAS xfilter</td>
<td>Vitis Vision library for the Gaussian + OTSU detector. Preserves edges while smoothening and calculates the optimum threshold between foreground and background pixels.</td>
<td>PL</td>
</tr>
<tr>
<td>Preprocess</td>
<td>VVAS xfilter</td>
<td>Vitis Vision library to convert a gray-scale image to a binary image and filter out noise from the image.</td>
<td>PL</td>
</tr>
<tr>
<td>CCA</td>
<td>VVAS xfilter</td>
<td>Vitis Vision library to determine the defective pixels in the image.</td>
<td>PL</td>
</tr>
<tr>
<td>Text2Overlay</td>
<td>VVAS xfilter</td>
<td><em>OpenCV</em> software library to calculate the defect density, determine the quality of the mango, and embed text as result into output images.</td>
<td>SW</td>
</tr>
</tbody>
</table><p>Each VVAS kernel library uses a configuration file in JSON format to read in static kernel
paramaters. There are two separate sets of configuration files, one set for the mono sensor,
the other set for the color sensor. The content of the files is identical except for the xclbin
path which is different depending on the sensor used. The below conifguration file snippets are
based on the mono sensor variants.
\10gige_vision_camera\docs
A common VVAS user meta data structure is defined <a class="reference external" href="https://github.com/Xilinx/mv-defect-detect/blob/master/defect-detect/src/vvas_dd_meta.h">here</a>.
It is used to exchange data between the individual kernels in the defect detect pipeline and
consists if the following fields:</p>
<ul class="simple">
<li><p>threshold: threshold value generated by the Otsu kernel</p></li>
<li><p>mango pixels: number of total mango pixels; generated by Preprocess kernel</p></li>
<li><p>defect pixels: number of defective mango pixels; generated by CCA kernel</p></li>
</ul>
<div class="section" id="gaussian-otsu-accelerator">
<h3>Gaussian_OTSU Accelerator<a class="headerlink" href="#gaussian-otsu-accelerator" title="Permalink to this heading">¶</a></h3>
<p>This kernel has two or three functions depending on whether the mono or color design is used:
RGB-to-Gray conversion (color variant only), Gaussian and OTSU; all functions are connected in
a streaming fashion.</p>
<p>In general, any smoothing filter smoothens the image, and affects the edges of the image. To
preserve the edges while smoothing, use a bilateral filter. In an analogous way as the
Gaussian filter, the bilateral filter also considers the neighboring pixels with weights assigned
to each of them. These weights have two components, the first of which is the same weighing used
by the Gaussian filter; the second component takes into account the difference in the intensity
between the neighbouring pixels and the evaluated one.</p>
<p>OTSU threshold is used to automatically perform clustering-based image thresholding or the
reduction of a gray-level image to a binary image. The algorithm assumes that the image contains
two classes of pixels following a bi-modal histogram (foreground pixels and background pixels), it
then calculates the optimum threshold separating the two classes.</p>
<p>The RGB-to-gray converter is used to convert the incoming RGB image to gray format for further
processing by the Gaussian and OTSU functions. The conversion parameters are hard-coded inside
the kernel library but configurable at the hardware kernel level.</p>
<p>The following figure depicts the Gaussian + OSTSU plugin software stack.</p>
<p><img alt="../../../_images/gaussian-plugin-sw-stack.png" src="../../../_images/gaussian-plugin-sw-stack.png" /></p>
<p>The following figure depicts the Gaussian + OTSU plugin data flow.</p>
<p><img alt="../../../_images/gaussian-plugin-dataflow.png" src="../../../_images/gaussian-plugin-dataflow.png" /></p>
<div class="section" id="kernel-interface">
<h4>Kernel Interface<a class="headerlink" href="#kernel-interface" title="Permalink to this heading">¶</a></h4>
<p>The Otsu kernel has the following programming interface:</p>
<ul class="simple">
<li><p>Image buffer pointer (input): Y8 (Gray) or RGB format depending on the design variant</p></li>
<li><p>Image buffer pointer (output): Y8 (Gray) format</p></li>
<li><p>Image height (input): set to 1080 by application code</p></li>
<li><p>Image width (input): set to 1920 by application code</p></li>
<li><p>Sigma (input): set to default value of 0.0 by kernel library code</p></li>
<li><p>Threshold (output): threshold value calculated by otsu</p></li>
<li><p>bgr2y8 (input): array of configuration paramaters for format RGB-to-Gray format conversion</p></li>
</ul>
<p>The Otsu kernel recieves and input image from the source plugin which can be either <em>filesrc</em>
or <em>v4l2src</em>. The input image pointer is extracted from the GST buffer object and passed down to
the kernel.</p>
<p>After the kernel completes, the output image is wrapped as a GST buffer object and sent to the
preprocess kernel. The otsu threshold value is wrapped a custom VVAS usr meta object and attached
to the GST buffer object.</p>
</div>
<div class="section" id="configuration-file">
<h4>Configuration File<a class="headerlink" href="#configuration-file" title="Permalink to this heading">¶</a></h4>
<p>The <em>otsu-accelerator.json</em> file is as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;xclbin-location&quot;</span><span class="p">:</span> <span class="s2">&quot;/lib/firmware/xilinx/kr260-mv-camera-mono/kr260-mv-camera-mono.xclbin&quot;</span><span class="p">,</span>
  <span class="s2">&quot;vvas-library-repo&quot;</span><span class="p">:</span> <span class="s2">&quot;/opt/xilinx/xlnx-app-kr260-mv-defect-detect/lib&quot;</span><span class="p">,</span>
  <span class="s2">&quot;element-mode&quot;</span><span class="p">:</span> <span class="s2">&quot;transform&quot;</span><span class="p">,</span>
  <span class="s2">&quot;kernels&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="s2">&quot;kernel-name&quot;</span><span class="p">:</span> <span class="s2">&quot;gaussian_otsu_accel:</span><span class="si">{gaussian_otsu_accel_1}</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="s2">&quot;library-name&quot;</span><span class="p">:</span> <span class="s2">&quot;libvvas_otsu.so&quot;</span><span class="p">,</span>
      <span class="s2">&quot;config&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;debug_level&quot;</span> <span class="p">:</span> <span class="mi">1</span>
      <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Configuration parameters:</p>
<ul class="simple">
<li><p>debug_level: Enable or disable debug log for the Kernel library.</p></li>
</ul>
</div>
</div>
<div class="section" id="preprocess-accelerator">
<h3>Preprocess Accelerator<a class="headerlink" href="#preprocess-accelerator" title="Permalink to this heading">¶</a></h3>
<p>The gray-scale image should be converted into a binary image with an appropriate threshold value.
The threshold function in the Vitis Vision library can perform the thresholding operation on the
input image. This yields an image that has a black background with the mango area in white.</p>
<p>The median blur filter acts as a non-linear digital filter that reduces noise. A filter size of N
outputs the median of the NxN neighborhood pixel values for each pixel. In this design, N is 3.</p>
<p>This plugin accepts the 1920x1080 Y8 image as input. The plugin applies the threshold binary
algorithm to convert the Y8 image to binary image by using the threshold value of the pixel.
Later, it applies the Median filter to remove salt and pepper noise.</p>
<p>For performance reasons, this kernel also performs part of the CCA operation, specifically the
forward pass. Both the threshold image as well as the CCA forward pass image are passed to the
CCA kernel.</p>
<p>The following figure depicts the Threshold + Median plugin software stack.</p>
<p><img alt="../../../_images/threshold-plugin-sw-stack.png" src="../../../_images/threshold-plugin-sw-stack.png" /></p>
<p>The following figure depicts the Threshold + Median plugin data flow.</p>
<p><img alt="../../../_images/threshold-median-plugin-dataflow.png" src="../../../_images/threshold-median-plugin-dataflow.png" /></p>
<div class="section" id="id1">
<h4>Kernel Interface<a class="headerlink" href="#id1" title="Permalink to this heading">¶</a></h4>
<p>The Preprocess kernel has the following programming interface:</p>
<ul class="simple">
<li><p>Image buffer pointer (input): Y8 (Gray) format</p></li>
<li><p>Image buffer pointer plane 0 (output): Y8 (Gray) format or first plane of NV16 format</p></li>
<li><p>Image buffer pointer plane 1 (output): second plane of NV16 format</p></li>
<li><p>Mango Pixels (output): number of total mango pixels</p></li>
<li><p>Threshold (input): Otsu threshold value</p></li>
<li><p>Max_value (input): set to default value of 255, configurable through JSON file</p></li>
<li><p>Image height (input): set to 1080 by application code</p></li>
<li><p>Image width (input): set to 1920 by application code</p></li>
<li><p>Image stride (input): set to 1920 or 2048 based on respective JSON config file</p></li>
</ul>
<p>The preprocess kernel receives an input image along with attached user meta from the otsu kernel.
The image buffer pointer and the otsu threshold value are extracted from the GST buffer and user
meta data object and passed down to the kernel.</p>
<p>After the kernel completes, the output image is wrapped as a GST buffer object and sent
to the next down stream kernel which can be either the cca kernel or a sink kernel like
<em>filesink</em> or <em>kmssink</em> for display. If the next kernel is a sink element, the output format is
set to Y8 (Gray); if the next kernel is the cca element, the output format is set to NV16. If the
sink element is a display, the stride value is set to 2048, otherwise it is set to 1920.
The stride value is obtained by selecting the respective JSON file via the kernels-config property.</p>
<p>When targeting a sink element, only the plane0 image output buffer generated by the binary
thresholding function is passed on as a Y8 buffer; the plane1 image output buffer generated by
the CCA forward pass function is written to a temporary buffer that is unused. When targeting
the CCA element, both the plane0 and plane1 buffers are transferred as a semi-planar NV16 buffer.
Both planes are consumed by the CCA kernel fo further processing.</p>
<p>The produced <em>Mango Pixels</em> value representing the total number of pixels associated with the
mango is wrapped as custom VVAS user meta object and attached to the GST buffer object.</p>
</div>
<div class="section" id="id2">
<h4>Configuration File<a class="headerlink" href="#id2" title="Permalink to this heading">¶</a></h4>
<p>The <em>preprocess-accelerator.json</em> and <em>preprocess-accelerator-stride.json</em> files are as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;xclbin-location&quot;</span><span class="p">:</span> <span class="s2">&quot;/lib/firmware/xilinx/kr260-mv-camera-mono/kr260-mv-camera-mono.xclbin&quot;</span><span class="p">,</span>
  <span class="s2">&quot;vvas-library-repo&quot;</span><span class="p">:</span> <span class="s2">&quot;/opt/xilinx/xlnx-app-kr260-mv-defect-detect/lib&quot;</span><span class="p">,</span>
  <span class="s2">&quot;element-mode&quot;</span><span class="p">:</span> <span class="s2">&quot;transform&quot;</span><span class="p">,</span>
  <span class="s2">&quot;kernels&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="s2">&quot;kernel-name&quot;</span><span class="p">:</span> <span class="s2">&quot;preprocess_accel:</span><span class="si">{preprocess_accel_1}</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="s2">&quot;library-name&quot;</span><span class="p">:</span> <span class="s2">&quot;libvvas_preprocess.so&quot;</span><span class="p">,</span>
      <span class="s2">&quot;config&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;debug_level&quot;</span> <span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="s2">&quot;max_value&quot;</span><span class="p">:</span> <span class="mi">255</span><span class="p">,</span>
        <span class="s2">&quot;stride_value&quot;</span><span class="p">:</span> <span class="mi">2048</span>
      <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Configuration parameters:</p>
<ul class="simple">
<li><p>debug_level: Enable or disable debug log for the Kernel library.</p></li>
<li><p>max_value: Maximum value to use with the THRESH_BINARY thresholding types.
For more information, click <a class="reference external" href="https://docs.opencv.org/master/d7/d1b/group__imgproc__misc.html#gae8a4a146d1ca78c626a53577199e9c57">here</a>.</p></li>
<li><p>stride_value: stride value in bytes; only present in <em>preprocess-accelerator-stride.json</em> file.
only used when sending output to the display.</p></li>
</ul>
</div>
</div>
<div class="section" id="cca-accelerator">
<h3>CCA Accelerator<a class="headerlink" href="#cca-accelerator" title="Permalink to this heading">¶</a></h3>
<p>The implemented Connected Component Analysis (CCA), is a custom solution to find the defective
pixels in the problem object. This algorithm considers few assumptions that the background must be
easily separable from the foreground object.</p>
<p>The custom CCA effectively analyses the components that are connected to the background pixels and
removes the background from the object and defective pixels. The aim is to send the following
output information from the function:</p>
<ul class="simple">
<li><p>defect image: image with only defect pixels marked as ‘255’ and both object pixels and background as ‘0’</p></li>
<li><p>object_pixels: total pixels of the object</p></li>
<li><p>defect_pixels: total defective pixels of the object</p></li>
</ul>
<p>For performance reasons, the CCA operation is split across the preprocess and the cca kernels. The
CCA forward pass is performed as part of the preprocess kernel whereas the CCA reverse pass along
with the AND’ing of the two passes is performed as part of this kernel.</p>
<p>The following figure depicts the CCA plugin software stack.</p>
<p><img alt="../../../_images/cca-plugin-sw-stack.png" src="../../../_images/cca-plugin-sw-stack.png" /></p>
<p>The following figure depicts the CCA plugin data flow.</p>
<p><img alt="../../../_images/cca-plugin-dataflow.png" src="../../../_images/cca-plugin-dataflow.png" /></p>
<div class="section" id="id3">
<h4>Kernel Interface<a class="headerlink" href="#id3" title="Permalink to this heading">¶</a></h4>
<p>The CCA kernel has the following programming interface:</p>
<ul class="simple">
<li><p>Image buffer pointer plane 0 (input): first plane of NV16 format</p></li>
<li><p>Image buffer pointer plane 1 (input): second plane of NV16 format</p></li>
<li><p>Image buffer pointer (output): Y8 (Gray) format</p></li>
<li><p>Defect Pixels (output): number of defective mango pixels</p></li>
<li><p>Image height (input): set to 1080 by application code</p></li>
<li><p>Image width (input): set to 1920 by application code</p></li>
<li><p>Image stride (input): set to 1920 or 2048 based on respective JSON config file</p></li>
</ul>
<p>The CCA kernel receives a semi-planar input image in NV16 format which really contains two Y8
images: the first plane contains the threshold image, the second plane contains the CCA forward
pass image plane. Attached to the buffer is the VVAS user meta from the otsu kernel. The pointers
to the two planes of the image buffer are extracted from the GST buffer and passed down to the
kernel.</p>
<p>After the kernel completes, the output image is wrapped as a GST buffer object and sent
to the <em>text2overlay</em> kernel. If the following sink element is the <em>kmssink</em> display element,
the stride value is set to 2048, otherwise it is set to 1920. This is done by selecting the
respective JSON file.</p>
<p>The <em>Mango Pixels</em> value is extracted from the incoming user meta object from the preprocess
kernel and copied into a new outgoing user meta object to be passed to the next element. In
addition, the generated <em>Defect Pixels</em> value generated by the cca function, representing the
total number of defective pixels in the mango, is copied into the same VVAS user meta object and
attached to the GST buffer.</p>
</div>
<div class="section" id="id4">
<h4>Configuration File<a class="headerlink" href="#id4" title="Permalink to this heading">¶</a></h4>
<p>The <em>cca-accelarator.json</em> and <em>cca-accelarator-stride.json</em> files are as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;xclbin-location&quot;</span><span class="p">:</span> <span class="s2">&quot;/lib/firmware/xilinx/kr260-mv-camera-mono/kr260-mv-camera-mono.xclbin&quot;</span><span class="p">,</span>
  <span class="s2">&quot;vvas-library-repo&quot;</span><span class="p">:</span> <span class="s2">&quot;/opt/xilinx/xlnx-app-kr260-mv-defect-detect/lib&quot;</span><span class="p">,</span>
  <span class="s2">&quot;element-mode&quot;</span><span class="p">:</span> <span class="s2">&quot;transform&quot;</span><span class="p">,</span>
  <span class="s2">&quot;kernels&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="s2">&quot;kernel-name&quot;</span><span class="p">:</span> <span class="s2">&quot;cca_custom_accel:</span><span class="si">{cca_custom_accel_1}</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="s2">&quot;library-name&quot;</span><span class="p">:</span> <span class="s2">&quot;libvvas_cca.so&quot;</span><span class="p">,</span>
      <span class="s2">&quot;config&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;debug_level&quot;</span> <span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="s2">&quot;stride_value&quot;</span> <span class="p">:</span> <span class="mi">2048</span>
      <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Configuration parameters:</p>
<ul class="simple">
<li><p>debug_level: Enable or disable debug log for the Kernel library.</p></li>
<li><p>stride_value: stride value in bytes; only present in <em>cca-accelerator-stride.json</em> file.
only used when sending output to the display.</p></li>
</ul>
</div>
</div>
<div class="section" id="defect-decision-text-overlay">
<h3>Defect Decision Text Overlay<a class="headerlink" href="#defect-decision-text-overlay" title="Permalink to this heading">¶</a></h3>
<p>The output of the CCA plugin is fed into the Defect Decision block, which determines the defect density and decides the quality of the mango. The block performs the following main operations:</p>
<ul class="simple">
<li><p>The ratio of blemished pixels to total mango pixels is calculated to determine how much of the mango’s surface area is covered with blemishes.</p></li>
<li><p>Defect Decision determines whether the ratio exceeds a user-defined, configurable threshold, to decide whether the mango is defected or not.</p></li>
<li><p>The results are embedded in the image as text overlay and the output is fed to the next plugin for the display.</p></li>
</ul>
<p>The following figure depicts the Defect Decision plugin software stack.</p>
<p><img alt="../../../_images/defect-decision-plugin-sw-stack.png" src="../../../_images/defect-decision-plugin-sw-stack.png" /></p>
<p>The following figure depicts the Defect Decision plugin data flow.</p>
<p><img alt="../../../_images/defect-decision-plugin-dataflow.png" src="../../../_images/defect-decision-plugin-dataflow.png" /></p>
<div class="section" id="id5">
<h4>Kernel Interface<a class="headerlink" href="#id5" title="Permalink to this heading">¶</a></h4>
<p>The text2overlay is a pure SW implemented using OpenCV functions; it does not have a hardware
kernel associated with it and thus no kernel programming interface.</p>
<p>The text2overlay kernel receives an input image in Y8 format along with attached VVAS user meta
from the CCA kernel extracted form the GST buffer object.</p>
<p>From the user meta objecte, the <em>Mango Pixels</em> and the <em>Defect Pixels</em> values are extracted to
calculate defect density and defect decision. The defect density is calculated as total number of
mango pixels divided by defective mango pixels. The defect decision is a boolean values set to
true if the defect density is greater than the defect threshold, or false otherwise. The defect
theshold is configurable through the JSON file; it is determined by calibrating the algorithm
against a golden data set.</p>
<p>Finally, the defect density and defect decision values are embedded into the input image as
text overlay using standard OpenCV functions. The modified input image is passed on to the
output of this element to be consumed by the sink element (in-place transformation).</p>
</div>
<div class="section" id="id6">
<h4>Configuration File<a class="headerlink" href="#id6" title="Permalink to this heading">¶</a></h4>
<p>The <em>text2overlay.json</em> file is as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;xclbin-location&quot;</span><span class="p">:</span> <span class="s2">&quot;/lib/firmware/xilinx/kr260-mv-camera-mono/kr260-mv-camera-mono.xclbin&quot;</span><span class="p">,</span>
  <span class="s2">&quot;vvas-library-repo&quot;</span><span class="p">:</span> <span class="s2">&quot;/opt/xilinx/xlnx-app-kr260-mv-defect-detect/lib&quot;</span><span class="p">,</span>
  <span class="s2">&quot;element-mode&quot;</span><span class="p">:</span><span class="s2">&quot;inplace&quot;</span><span class="p">,</span>
  <span class="s2">&quot;kernels&quot;</span> <span class="p">:[</span>
    <span class="p">{</span>
      <span class="s2">&quot;library-name&quot;</span><span class="p">:</span><span class="s2">&quot;libvvas_text2overlay.so&quot;</span><span class="p">,</span>
      <span class="s2">&quot;config&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;debug_level&quot;</span> <span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="s2">&quot;font_size&quot;</span> <span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="s2">&quot;font&quot;</span> <span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
        <span class="s2">&quot;x_offset&quot;</span> <span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="s2">&quot;y_offset&quot;</span> <span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
        <span class="s2">&quot;defect_threshold&quot;</span> <span class="p">:</span> <span class="mf">0.14</span><span class="p">,</span>
        <span class="s2">&quot;is_acc_result&quot;</span> <span class="p">:</span> <span class="mi">0</span>
      <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Configuration parameters:</p>
<ul class="simple">
<li><p>debug_level: Enable or disable debug log for the Kernel library.</p></li>
<li><p>font_size: User configuration to change the font size.</p></li>
<li><p>font: User configuration to change the supported font type.</p></li>
<li><p>x_offset: The X co-ordinate from where the text starts writing.</p></li>
<li><p>y_offset: The Y co-ordinate from where the text starts writing.</p></li>
<li><p>defect_threshold: The defect density threshold to calculate the defect. If the defect value is  more than the threshold, it falls under defect category.</p></li>
<li><p>is_acc_result: Flag to display the accumulated result. If the value is 0, then the accumulated result will not be displayed.
For more information <a class="reference external" href="https://docs.opencv.org/3.4/d0/de1/group__core.html#ga0f9314ea6e35f99bb23f29567fc16e11">see</a>.</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="next-steps">
<h2>Next Steps<a class="headerlink" href="#next-steps" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p>Go back to the <a class="reference internal" href="hw_arch_accel_dd.html"><span class="doc">Hardware Architecture of the Accelerator</span></a></p></li>
<li><p>Go back to the <a class="reference internal" href="sw_arch_platform_dd.html"><span class="doc">Software Architecture of the Platform</span></a></p></li>
</ul>
<hr class="sphinxhide"></hr><p class="sphinxhide" align="center"><sub>Copyright © 2023–2024 Advanced Micro Devices, Inc.</sub></p><p class="sphinxhide" align="center"><sup><a href="https://www.amd.com/en/corporate/copyright">Terms and Conditions</a></sup></p></div>
</div>


           </div>
          </div>
          
				  
				  <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="sw_arch_platform_dd.html" class="btn btn-neutral float-left" title="Software Architecture of the Platform" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="debug.html" class="btn btn-neutral float-right" title="Debug" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022-2024, Advanced Micro Devices, Inc.
      <span class="lastupdated">Last updated on July 19, 2024.
      </span></p>
  </div>



										<div class="aem-Grid aem-Grid--16">
											<div class="aem-GridColumn aem-GridColumn--xxxlarge--none aem-GridColumn--xsmall--16 aem-GridColumn--offset--xsmall--0 aem-GridColumn--xlarge--none aem-GridColumn--xxlarge--none aem-GridColumn--default--none aem-GridColumn--offset--large--1 aem-GridColumn--xlarge--12 aem-GridColumn--offset--default--0 aem-GridColumn--xxlarge--10 aem-GridColumn--offset--xlarge--2 aem-GridColumn--offset--xxlarge--3 aem-GridColumn--offset--xxxlarge--4 aem-GridColumn--xsmall--none aem-GridColumn--large--none aem-GridColumn aem-GridColumn--large--14 aem-GridColumn--xxxlarge--8 aem-GridColumn--default--16">
												<div class="container-fluid sub-footer">

													                    <div class="row">
                        <div class="col-xs-24">
                          <p><a target="_blank" href="https://www.amd.com/en/corporate/copyright">Terms and Conditions</a> | <a target="_blank" href="https://www.amd.com/en/corporate/privacy">Privacy</a> | <a target="_blank" href="https://www.amd.com/en/corporate/cookies">Cookie Policy</a> | <a target="_blank" href="https://www.amd.com/en/corporate/trademarks">Trademarks</a> | <a target="_blank" href="https://www.amd.com/system/files/documents/statement-human-trafficking-forced-labor.pdf">Statement on Forced Labor</a> | <a target="_blank" href="https://www.amd.com/en/corporate/competition">Fair and Open Competition</a> | <a target="_blank" href="https://www.amd.com/system/files/documents/amd-uk-tax-strategy.pdf">UK Tax Strategy</a> | <a target="_blank" href="https://docs.xilinx.com/v/u/9x6YvZKuWyhJId7y7RQQKA">Inclusive Terminology</a> | <a href="#cookiessettings" class="ot-sdk-show-settings">Cookies Settings</a></p>
                        </div>
                    </div>
												</div>
											</div>
										</div>
										
</br>


  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>